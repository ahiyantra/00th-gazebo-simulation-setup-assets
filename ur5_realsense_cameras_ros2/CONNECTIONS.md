# Background knowledge.

01. Intel's RealSense D435 camera is an RGBD (red/green/blue/depth) camera. It generates several types of data that can be used: color images, depth images, depth cloud, point cloud.

02. Ignition Gazebo Fortress (6.x) has support for creating virtual RGBD cameras, inlcuding the D415 & D435 cameras.

03. ROS2's rviz2 has support for processing data from virtual RGBD cameras through sensory bridge connections.

04. Messages generated by camera topics can be visualized through dedicated "image display" plug-ins, which are available for both gazebo & rviz but separately.

# Data flow.

01. gazebo simuation -> gazebo topic -> bridge -> ros topic -> rviz simulation

02. setting up gazebo -> setting up a suitable bridge between gazebo & ros topics -> setting up rviz

03. For virtual cameras, the image bridge allows one-way communication & the paramter bridge allows two-way communication.

04. In order for messages to be sent through publishing & received through subscription with the help of topics & bridges used for communication, the simulation needs to be played first.

# Terminal commands.

01. Open three terminal windows (one for ignition gazebo fortress, one for ROS2's paramter bridge & one for rviz2) attached to the -01st-redacted-term- project's docker container.
02. We're assuming that the demo-01 files are placed at the following system address: /-01st-redacted-term-_rl_pickplace/src_code_1/-01st-redacted-term-_rl_grasp_reach/realsense_cameras_ros2/demo-01/
03. Commands for first terminal window after going to where the demo files are placed:
    $ ign gazebo demo-01.sdf
04. Commands for second terminal window to map communication topics from gazebo to ros2:
    $ ros2 run ros_gz_bridge parameter_bridge /camera@sensor_msgs/msg/Image@gz.msgs.Image /camera_info@sensor_msgs/msg/CameraInfo@gz.msgs.CameraInfo /rgbd_camera/image@sensor_msgs/msg/Image@gz.msgs.Image /rgbd_camera/camera_info@sensor_msgs/msg/CameraInfo@gz.msgs.CameraInfo /rgbd_camera/depth_image@sensor_msgs/msg/Image@gz.msgs.Image /rgbd_camera/points@sensor_msgs/msg/PointCloud2@gz.msgs.PointCloudPacked
05. Commands for third terminal window to display messages received from ign gz to ros2's rviz2:
    $ rviz2
06. Load the configuration files (a file named something like "demo-01[dot]rviz" or "rgbd-camera_regular-bridge[dot]rviz") for ros2's rviz2 from the file menu.
07. Play the simulation in gazebo to begin sending messages through topics from ign gz to ros2's rviz2.

# Connecting the USB-based intel realsense D435 camera device to the viewer app through WSL2.

The default linux kernel in WSL 2 comes without the additional linux modules necessary for connecting with either USB-based hardware or camera devices, so a custom linux kernel needs to be built with support for both USB-based hardware and camera devices by following the specific steps listed with dedicated free & open-source software projects, such as "usbipd-win" & "wsl2_linux_kernel_usbcam_enable_conf", in order to connect a USB-based camera device, such as intel realsense D435, to a WSL 2 instance for use with intel's realsense viewer app.

# Connecting the USB-based intel realsense D435 camera device to ROS2's RVIZ2 app through WSL2.

The device hardware ports need to be mirrored from windows 10 into WSL2, followed by mirroring from WSL2 into the project's docker container. The connected USB-based devices avaialble to windows 10 can then be accessed from inside the project's docker container through WSL2. Some linux packages, including "usbtils", need to be installed on the project's docker container in order to make the connections possible. The official wrapper software package for intel's realsense camera devices makes it possible for them to be treated like nodes for ROS2's RVIZ2 to connect with, which allows subscribing to their topics for receiving broadcasts.

# Using python launch files for seting up either gazebo simulation or hardware devices.

There are two python launch files. One is for the ignition gazebo simulation of intel realsense, named "rs-igngz-test[dot]launch[dot]py". One is for the actual hardware devices of intel realsense, named "rs-hardware-test[dot]launch[dot]py". There's also a bash script for setting up the necessary packages that allow the actual hardware devices to be used through the USB links before the related python launch file can be used.

# Using the 04th version of the project's docker image built by extending the 03rd version.

The project's older docker image version used during develeopment (named "dock_im_pickplace_03_3") was extended to create a newer version with the necessary packages (named "dock_im_pickplace_03_4"), in order to make it so that the "irs_hardware[dot]sh" script won't need to be run anymore before using the python launch file which is meant for using the actual intel realsense hardware devices through the USB links.

# Steps for the windows 10 powershell terminal, preferably as administrator.

<after rebuilding the WSL kernel & finding the USB device directory address>

usbipd list

usbipd bind --busid <usb_id>

usbipd attach --wsl --busid <usb_id>

usbipd detach --busid <usb_id>

# Steps for the ubuntu 22 bash terminal, preferably as administrator.

<after rebuilding the WSL kernel & finding the USB device directory address>

lsusb

lsblk

find /dev/bus/

docker run --interactive --tty --privileged --rm --network host --ipc host --security-opt "seccomp=unconfined" --env DISPLAY="$DISPLAY" --volume="$HOME/.Xauthority:/root/.Xauthority:rw" --volume="/tmp/.X11-unix:/tmp/.X11-unix" --volume="/home/ubuntu/Downloads:/root/ws/Downloads" --device=<usb_address> dock_im_pickplace_03_3:12032024

sudo apt-get install usbutils -y

lsusb

lsblk

find /dev/bus/

sudo mkdir -p /etc/apt/keyrings

curl -sSf https://librealsense.intel.com/Debian/librealsense.pgp | sudo tee /etc/apt/keyrings/librealsense.pgp > /dev/null

echo "deb [signed-by=/etc/apt/keyrings/librealsense.pgp] https://librealsense.intel.com/Debian/apt-repo `lsb_release -cs` main" | sudo tee /etc/apt/sources.list.d/librealsense.list

sudo apt-get update

sudo apt-get install librealsense2-dkms librealsense2-utils librealsense2-dev librealsense2-dbg -y

realsense-viewer

sudo apt install ros-humble-realsense2-* -y

ros2 run realsense2_camera realsense2_camera_node
ros2 run realsense2_camera realsense2_camera_node --ros-args -p enable_color:=false -p spatial_filter.enable:=true -p temporal_filter.enable:=true

ros2 launch realsense2_camera rs_launch.py
ros2 launch realsense2_camera rs_launch.py depth_module.depth_profile:=1280x720x30 pointcloud.enable:=true

# Relevant links.

01. https://app.gazebosim.org/OpenRobotics/fuel/models/Intel%20RealSense%20D435 ~ "Intel RealSense D435 By OpenRobotics"

02. https://github.com/gazebosim/ros_gz/tree/ros2/ros_gz_sim_demos#rgbd-camera ~ a sample virtual RGBD camera, different from D435

03. https://github.com/gazebosim/ros_gz/blob/ros2/ros_gz_point_cloud/examples/rgbd_camera.sdf ~ a sample virtual RGBD camera, different from D435

04. https://github.com/PINTO0309/wsl2_linux_kernel_usbcam_enable_conf ~ "Configuration file to build the kernel to access the USB camera connected to the host PC using USBIP from inside the WSL2."

05. https://github.com/IntelRealSense/realsense-ros ~ "ROS Wrapper for Intel(R) RealSense(TM) Cameras"

06. https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md ~ "librealsense | Linux Distribution"

07. https://askubuntu.com/questions/668829/lsusb-command-not-found

# Relevant notes.

01. The virtual camera model's SDF file obtained from Gazebo's Fuel website is incomplete. It needs communication topics to be added separately.

02. It's possible for the virtual camera model by OpenRobotics to disappear from Gazebo's Fuel website, so an offline copy of it needs to be used.

03. If the list of topics for gazebo's image display plug-in is empty, then click on the refresh option.

04. The virtual D435 camera is able to send depth, sight and point cloud data from ign gz to ros2's rviz2 even without the "tf" (transform) data. At the same time, providing the fixed frame address for configuration of ros2's rviz2 is necessary for the point cloud data but not for the depth and sight data.

05. Fixed Frame (for configuration of ros2's rviz2 with the ign gz sim) = "model_name/link_name/sensor_name" = "Intel-RealSense-D435_openrobotics/d435_link/rgbd_camera"

06. Fixed Frame (for configuration of ros2's rviz2 with the USB device) = "camera_link"

07. The depth image, color image, depth cloud and point cloud for the virtual and actual realsense cameras is practically the same overll but a difference in the scale of things between simulated world and actual world can result in confusion about their sensor data.

# Author details.

S. S. W. (it23139[at]lbtu.lv)
